{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elevating Talent Matching with Word2Vec Word Embedding with Gensim in Python.\n",
    "In the world of hiring, companies face a big challenge: sorting through heaps of resumes to find the right candidates. It's a time-consuming process, and sometimes, they end up with the wrong fit for the job. Our project aims to change that by using smart computer techniques to help with hiring.\n",
    "\n",
    "We've learned how to use fancy computer tricks to quickly go through resumes. By teaching a computer to understand resumes and job descriptions, we can find out which candidates are best suited for a particular job. This means less time wasted and more chances of finding the perfect match for the job.\n",
    "\n",
    "Our project is a game-changer for hiring. It makes the whole process faster and easier. With our computer magic, companies can focus on talking to the best candidates instead of spending hours going through resumes. It's a win-win for everyone involved, making hiring smoother and more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Resume Data Loading.\n",
    "Before we start our analysis, first, we need to view the dataset. It is essential to view the data and check the columns. Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Resume_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16852973</td>\n",
       "      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22323967</td>\n",
       "      <td>HR SPECIALIST, US HR OPERATIONS      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33176873</td>\n",
       "      <td>HR DIRECTOR       Summary      Over 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27018550</td>\n",
       "      <td>HR SPECIALIST       Summary    Dedica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17812897</td>\n",
       "      <td>HR MANAGER         Skill Highlights  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>33578873</td>\n",
       "      <td>SALES       Summary    I am looking f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>27607632</td>\n",
       "      <td>SALES       Summary    Self-motivated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>23760084</td>\n",
       "      <td>SALES       Summary     General Sales...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>30083943</td>\n",
       "      <td>SALES       Professional Summary     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>20552814</td>\n",
       "      <td>SALES         Summary    Enthusiastic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                         Resume_str\n",
       "0    16852973           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...\n",
       "1    22323967           HR SPECIALIST, US HR OPERATIONS      ...\n",
       "2    33176873           HR DIRECTOR       Summary      Over 2...\n",
       "3    27018550           HR SPECIALIST       Summary    Dedica...\n",
       "4    17812897           HR MANAGER         Skill Highlights  ...\n",
       "..        ...                                                ...\n",
       "995  33578873           SALES       Summary    I am looking f...\n",
       "996  27607632           SALES       Summary    Self-motivated...\n",
       "997  23760084           SALES       Summary     General Sales...\n",
       "998  30083943           SALES       Professional Summary     ...\n",
       "999  20552814           SALES         Summary    Enthusiastic...\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#--- Read in dataset ----\n",
    "df = pd.read_csv(\"Resume.csv\")\n",
    "\n",
    "#--- Inspect data ---\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Empowering Resumes with Word2Vec Word Embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building and Saving Word Embeddings for Resumes using Word2Vec.\n",
    "\n",
    "Task is to tokenize the text in the 'Resume_str' column of DataFrame df into lowercase words. Train a Word2Vec model on the tokenized resume data. Set parameters: vector size (100), window size (5), min word count (1), using 4 CPU cores. Save the trained Word2Vec model as \"resume_word2vec.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nandi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\nandi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download 'punkt' resource for tokenization\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Tokenize the text in the 'Resume_str' column of DataFrame df into lowercase words\n",
    "tokenized_resumes = df['Resume_str'].apply(lambda x: word_tokenize(x.lower()))\n",
    "\n",
    "# Train a Word2Vec model on the tokenized resume data\n",
    "word2vec_model = Word2Vec(\n",
    "    sentences=tokenized_resumes,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    workers=4\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "word2vec_model.save(\"resume_word2vec.model\")\n",
    "print(\"Model trained and saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Job Description Precision: Navigating Talent Waters with Word2Vec.\n",
    "\n",
    "Creating a Vector Representation for a User-Provided Job Description using Pre-trained Word2Vec Model.\n",
    "\n",
    "- Your task is to load the pre-trained Word2Vec model named \"resume_word2vec.model\" using Gensim.\n",
    "\n",
    "- Load the user-provided job description as a string. Tokenize the job description into lowercase words. Check if the token is present in the Word2Vec model's vocabulary (model.wv). If present, retrieve the word vector. Calculate the mean of all the word vectors to generate a vector representation for the entire job description.\n",
    "\n",
    "- Convert the generated vector representation to a Numpy array. The variable 'user_provided_vector' now contains a numerical representation of the user-provided job description based on the pre-trained Word2Vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector representation for the job description: [-0.54823947  0.3156618  -0.15656994  0.00200185  0.16903327 -0.78497076\n",
      "  0.04194819  0.86971027 -0.20658605 -0.31736094  0.07435112 -0.29552442\n",
      " -0.36488298  0.39208832  0.40816435 -0.3338771   0.05262439 -0.11582508\n",
      " -0.06887101 -0.8429761  -0.5104074  -0.3097133  -0.06228101  0.50397205\n",
      "  0.0930154   0.00915964 -0.28422952 -0.2644952  -0.41796187  0.05258517\n",
      "  0.4790165   0.18670195 -0.02552393 -0.42283142 -0.22452849  0.26726878\n",
      " -0.14724356 -0.556589    0.20661734 -0.37638184  0.15845901 -0.556226\n",
      " -0.19911318 -0.3231706   0.1520997  -0.22602019 -0.09159579 -0.1312308\n",
      "  0.05002306  0.36709243  0.2376847  -0.12050234 -0.58711296  0.36037737\n",
      "  0.14033702  0.48992628  0.2245814  -0.24120715 -0.18965845  0.35196248\n",
      "  0.17626645 -0.20186383  0.18303522  0.13773578 -0.36581966  0.40484056\n",
      "  0.32192183  0.06897336 -0.01661446  0.48803094 -0.12171568  0.30195642\n",
      "  0.28555056 -0.24468781  0.46122393  0.6706288  -0.35504895 -0.05604719\n",
      " -0.18316762 -0.01921594  0.22191562  0.2202026  -0.03006766  0.74469906\n",
      " -0.13630722 -0.02951673 -0.19929577  1.1555473   0.8681266   0.03813625\n",
      "  0.5296881   0.37139973  0.19322966 -0.09103804  0.9096782   0.5855688\n",
      "  0.5979838  -0.5049093   0.14666615 -0.40286562]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# # Load the pre-trained Word2Vec model\n",
    "my_model = Word2Vec.load(\"resume_word2vec.model\")\n",
    "\n",
    "# # Load the user-provided job description\n",
    "job_description = \"\"\"We are seeking a highly motivated and detail-oriented Data Analyst to join our team in Delhi,\n",
    "India. As a Data Analyst, you will be responsible for analyzing large datasets, identifying trends, \n",
    "and generating insights to drive business decisions. You should have strong skills in data analysis, SQL (MySQL), \n",
    "and data management. Proficiency in office management and basic knowledge of data science concepts is also required. \n",
    "This is an entry-level position, and we offer an annual compensation of 3-6 LPA. \n",
    "A bachelor's degree is the minimum qualification required for this role. \n",
    "Join us and contribute to our data-driven decision-making process.\"\"\"\n",
    "\n",
    "# Tokenize the user-provided job description\n",
    "tokenized_job_description = word_tokenize(job_description.lower())\n",
    "\n",
    " #Retrieve word vectors for tokens present in the model's vocabulary\n",
    "word_vectors = [word2vec_model.wv[token] for token in tokenized_job_description if token in word2vec_model.wv]\n",
    "\n",
    "# Calculate the mean of all the word vectors to generate a vector representation for the entire job description\n",
    "if word_vectors:\n",
    "    mean_vector = np.mean(word_vectors, axis=0)\n",
    "else:\n",
    "    mean_vector = np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "# Convert the generated vector representation to a Numpy array\n",
    "user_provided_vector = np.array(mean_vector)\n",
    "\n",
    "print(\"Vector representation for the job description:\", user_provided_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
