{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elevating Talent Matching with Word2Vec Word Embedding with Gensim in Python.\n",
    "In the world of hiring, companies face a big challenge: sorting through heaps of resumes to find the right candidates. It's a time-consuming process, and sometimes, they end up with the wrong fit for the job. Our project aims to change that by using smart computer techniques to help with hiring.\n",
    "\n",
    "We've learned how to use fancy computer tricks to quickly go through resumes. By teaching a computer to understand resumes and job descriptions, we can find out which candidates are best suited for a particular job. This means less time wasted and more chances of finding the perfect match for the job.\n",
    "\n",
    "Our project is a game-changer for hiring. It makes the whole process faster and easier. With our computer magic, companies can focus on talking to the best candidates instead of spending hours going through resumes. It's a win-win for everyone involved, making hiring smoother and more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Resume Data Loading.\n",
    "Before we start our analysis, first, we need to view the dataset. It is essential to view the data and check the columns. Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Resume_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16852973</td>\n",
       "      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22323967</td>\n",
       "      <td>HR SPECIALIST, US HR OPERATIONS      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33176873</td>\n",
       "      <td>HR DIRECTOR       Summary      Over 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27018550</td>\n",
       "      <td>HR SPECIALIST       Summary    Dedica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17812897</td>\n",
       "      <td>HR MANAGER         Skill Highlights  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>33578873</td>\n",
       "      <td>SALES       Summary    I am looking f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>27607632</td>\n",
       "      <td>SALES       Summary    Self-motivated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>23760084</td>\n",
       "      <td>SALES       Summary     General Sales...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>30083943</td>\n",
       "      <td>SALES       Professional Summary     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>20552814</td>\n",
       "      <td>SALES         Summary    Enthusiastic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                         Resume_str\n",
       "0    16852973           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...\n",
       "1    22323967           HR SPECIALIST, US HR OPERATIONS      ...\n",
       "2    33176873           HR DIRECTOR       Summary      Over 2...\n",
       "3    27018550           HR SPECIALIST       Summary    Dedica...\n",
       "4    17812897           HR MANAGER         Skill Highlights  ...\n",
       "..        ...                                                ...\n",
       "995  33578873           SALES       Summary    I am looking f...\n",
       "996  27607632           SALES       Summary    Self-motivated...\n",
       "997  23760084           SALES       Summary     General Sales...\n",
       "998  30083943           SALES       Professional Summary     ...\n",
       "999  20552814           SALES         Summary    Enthusiastic...\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#--- Read in dataset ----\n",
    "df = pd.read_csv(\"Resume.csv\")\n",
    "\n",
    "#--- Inspect data ---\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Empowering Resumes with Word2Vec Word Embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building and Saving Word Embeddings for Resumes using Word2Vec.\n",
    "\n",
    "Task is to tokenize the text in the 'Resume_str' column of DataFrame df into lowercase words. Train a Word2Vec model on the tokenized resume data. Set parameters: vector size (100), window size (5), min word count (1), using 4 CPU cores. Save the trained Word2Vec model as \"resume_word2vec.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nandi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\nandi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "\n",
    "# Download 'punkt' resource for tokenization\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Tokenize the text in the 'Resume_str' column of DataFrame df into lowercase words\n",
    "tokenized_resumes = df['Resume_str'].apply(lambda x: word_tokenize(x.lower()))\n",
    "\n",
    "# Train a Word2Vec model on the tokenized resume data\n",
    "word2vec_model = Word2Vec(\n",
    "    sentences=tokenized_resumes,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    workers=4\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "word2vec_model.save(\"resume_word2vec.model\")\n",
    "print(\"Model trained and saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
